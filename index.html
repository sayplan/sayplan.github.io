<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning">
  <meta name="keywords" content="SayPlan, 3D Scene Graphs, Large Language Models, LLM, Task Planning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://krishanrana.github.io">Krishan Rana</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/jhavl">Jesse Haviland</a><sup>1,3</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/oravus">Sourav Garg</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/jc211">Jad Abou-Chakra</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cs.adelaide.edu.au/~ianr/">Ian Reid</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://nikosuenderhauf.github.io/">Niko Suenderhauf</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>QUT Centre for Robotics</span>
            <span class="author-block"><sup>2</sup>University of Adelaide</span>
            <span class="author-block"><sup>3</sup>CSIRO Data61</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2307.06135"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/3aMgpqnD2RY?si=0re6L_st-x-yH_Me"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
<!--               <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay controls muted loop playsinline height="100%">
        <source src="Images/sayplan_compressed.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">SayPlan</span> scales the grounding of task plans generated by large language models to <b>multi-room</b> and <b>multi-floor</b> environments using 3D scene graph representations.
      </h2>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, <b>multi-floor</b>, and <b>multi-room</b> environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a <em>semantic search</em> for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an <em>iterative re-planning</em> pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors, 36 rooms and 140 objects, and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a real-world mobile manipulator robot to execute.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Approach</h2>

        <div class="content has-text-justified">
            <p style="text-align:center;">
                <image src="Images/sayplan_flow.png" class="img-responsive">        	   
            </p>
          <p>
            This work is motivated by the need to ground task plans generated by LLMs in large-scale, multi-floor and multi-room environments. 3DSGs capture a rich topological and hierarchically-organised semantic graph representation of such environments with the versatility to encode the necessary information required for task planning including object state, predicates, affordances and attributes using natural language -- suitable for parsing by an LLM. We leverage a JSON representation of this graph as input to a pre-trained LLM, however, to ensure the <i>scalability</i> of the plans to larger scenes, we introduce two key components which exploit the hierarchical nature of 3DSGs: semantic search and iterative re-planning. 
          </p>
        </div>


        
        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Semantic Search</h3>
        <div class="columns">
            <!-- for the gif -->
            <div class="column is-8">
                <img src="Images/search.gif" alt="semantic search gif">
            </div>
            <!-- for the text -->
            <div class="column is-4" style="display: flex; align-items: center;">
                <div class="content has-text-justified">
                    <p>
                        Given a natural language instruction, the LLM conducts a semantic search for a task-relevant subgraph which contains the assets and objects that are required for planning. This is done by manipulating the nodes of a <i>collapsed</i> 3D scene graph through <code>expand</code> and <code>contract</code> API function calls -- thus making it feasible to plan over increasingly large-scale environments. In doing so, the LLM maintains focus on the small, informative subgraph, during planning, without exceeding its token limit.
                    </p>
                </div>
            </div>
        </div>
    <!--/ Animation. -->
    <h3 class="title is-4" style="text-align: left;">Iterative Re-planning</h3>
          <div class="columns">
            <!-- for the text -->
            <div class="column is-4" style="display: flex; align-items: center;">
              <div class="content has-text-justified">
                <p>
                  To ensure the executability of the proposed plan, we iteratively verify the plan using feedback from a scene graph simulator to correct for any unexecutable actions such as -  missing to open the fridge before placing something into it; thus avoiding planning failures due to inconsistencies, hallucinations, or violations of the physical constraints imposed by the environment. We additionally relax the need for the LLM to produce long navigation sequences by incorporating an existing path planner such as Dijkstra to connect high-level nodes generated by the LLM.
                </p>
              </div>
            </div>
            <!-- for the gif -->
            <div class="column is-8">
              <img src="Images/planning.gif" alt="semantic search gif">
            </div>
          </div>
        <!--/ Re-rendering. -->

      </div>
    </div>

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <p>
            We demonstrate the ability to autonomously deploy the generated plan on a real mobile manipulator robot using a visually grounded motion controller. We utilise a pre-constructed 3D scene graph of an office floor spanning 36 rooms and containing 150 different assets and objects that the agent can interact with. Note the ability of the agent to generate grounded plans across multiple rooms. In all the videos shown, the robot operates fully autonomously using visual feedback from its in-hand camera for manipulation and localises itself within the scene graph using its onboard laser scanner.
          </p>

        </div>
      </div>
    </div>

    <section class="hero is-light is-small">
        <div class="hero-body">
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
              <div class="item item-steve">
                <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
                  <source src="Images/peter_banana_final.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-chair-tp">
                <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
                  <source src="Images/chip_niko_replace.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-chair-tp">
                <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
                  <source src="Images/three_bottles_final.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-shiba">
                <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
                  <source src="Images/soda_spill_simple.mp4"
                          type="video/mp4">
                </video>
              </div>
              <div class="item item-fullbody">
                <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
                  <source src="Images/dimity_stapler.mp4"
                          type="video/mp4">
                </video>
              </div>
            </div>
          </div>
        </div>
      </section>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
<div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
rana2023sayplan,
title={SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning},
author={Krishan Rana and Jesse Haviland and Sourav Garg and Jad Abou-Chakra and Ian Reid and Niko Suenderhauf},
booktitle={7th Annual Conference on Robot Learning},
year={2023},
url={https://openreview.net/forum?id=wMpOMO0Ss7a}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>

    <div class="columns is-centered">
      <div class="column is-8">
<!--         <div class="institute-logos has-text-centered"> -->
        <div class="content has-text-centered">
          <img src="./Images/qcr.png" alt="Institute 1" style="width:200px; margin:20px;">
          <img src="./Images/uoa.png" alt="Institute 2" style="width:200px; margin:20px;">
          <img src="./Images/data61.png" alt="Institute 3" style="width:200px; margin:20px;">
        </div>
      </div>
    </div>


      <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website template borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
    
  </div>
</footer>

</body>
</html>
