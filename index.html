<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>SayPlan: Grounding Language in Large Scale
Robotic Plans Using 3D Scene Graphs</title>


  <!-- Google Tag Manager -->
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-PFJ2DFW');</script>
  <!-- End Google Tag Manager -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/vlmaps_icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PFJ2DFW" height="0" width="0"
      style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SayPlan: Grounding Large Language Models Using 3D Scene Graphs for Scalable Task Planning</h1>



<section class="section">
  <div class="container is-max-desktop">
<!--     Paper video. -->
<div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
<!--         <h2 class="title is-3">Video</h2> -->
        <div class="publication-video">
          <video id="v0" width="100%" autoplay controls muted loop playsinline>
                       <source src="Images/sayplan_compressed.mp4" type="video/mp4">
          </video>
        </div>
      </div>
</div>
<!--/ Paper video. -->




	  
<br>

	  
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, <b>multi-floor</b>, and <b>multi-room</b> environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a <em>semantic search</em> for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an <em>iterative re-planning</em> pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors, 36 rooms and 140 objects, and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a real-world mobile manipulator robot to execute.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->  
  </div>

<br>
<br>


    <!-- Approach. -->
    <div class="columns">
      <div class="column is-full-width">
        <h2 class="title is-3" style="text-align: left;">Approach</h2>

        

        <!-- Interpolating. -->
        <div class="content has-text-justified">

          <p style="text-align:center;">
            <image src="Images/sayplan_flow.png" class="img-responsive">        	   
          </p>

          <p>
            We are motivated by the need to ground task plans generated by LLMs in large-scale, <b>multi-floor</b> and <b>multi-room</b> environments. 3DSGs capture a rich topological and hierarchically-organised semantic graph representation of such environment with the versatility to encode the necessary information required for task planning including object state, predicates, affordances and attributes using natural language -- suitable for parsing by an LLM. We can leverage a JSON representation of this graph as input to a pre-trained LLM, however, to ensure the <i>scalability</i> of the plans to larger scenes, we introduce two key components which exploit the hierarchical nature of 3DSGs: semantic search and iterative re-planning. 
            
          </p>



  
        </div>

        
        

        <br/>
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4" style="text-align: left;">Semantic Search</h3>
        <div class="columns">
            <!-- for the gif -->
            <div class="column is-8">
                <img src="Images/search.gif" alt="semantic search gif">
            </div>
            <!-- for the text -->
            <div class="column is-4" style="display: flex; align-items: center;">
                <div class="content has-text-justified">
                    <p>
                        The LLM conducts a semantic search for a task-relevant subgraph which contains the required assets and objects that are required for planning. This is done by manipulating the nodes of a <i>collapsed</i> graph through <code>expand</code> and <code>contract</code> API function calls -- thus making it feasible to plan over increasingly large-scale environments. In doing so, the LLM maintains focus on the small, informative subgraph, during planning, without exceeding its token limit.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Re-rendering. -->


        <!-- Re-rendering. -->
        <h3 class="title is-4" style="text-align: left;">Iterative Re-planning</h3>
          <div class="columns">
            <!-- for the text -->
            <div class="column is-4" style="display: flex; align-items: center;">
              <div class="content has-text-justified">
                <p>
                  To ensure the executability of the proposed plan, we iteratively verify the plan using feedback from a scene graph simulator to correct for any unexecutable actions such as -  missing to open the fridge before placing something into it; thus avoiding planning failures due to inconsistencies, hallucinations, or violations of the physical constraints imposed by the environment. We additionally relax the need for the LLM to produce long navigation sequences by incorporating an existing path planner such as Dijkstra to connect high-level nodes generated by the LLM.
                </p>
              </div>
            </div>
            <!-- for the gif -->
            <div class="column is-8">
              <img src="Images/planning.gif" alt="semantic search gif">
            </div>
          </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="text-align: left;">Results</h2>

        <section class="hero is-light is-small">
          <div class="hero-body">
            <div class="container">
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-steve">
                  <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
                    <source src="Images/sayplan_compressed.mp4"
                            type="video/mp4">
                  </video>
                </div>
                <div class="item item-chair-tp">
                  <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
                    <source src="Images/sayplan_compressed.mp4"
                            type="video/mp4">
                  </video>
                </div>
                <div class="item item-shiba">
                  <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
                    <source src="Images/sayplan_compressed.mp4"
                            type="video/mp4">
                  </video>
                </div>
                <div class="item item-fullbody">
                  <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
                    <source src="Images/sayplan_compressed.mp4"
                            type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
          </div>
        </section>



      </div>
    </div>

    



<!-- 
<p style="text-align:center;">
	<image src="Images/SayPlan_Overview_Simple.png" class="img-responsive">        	   
</p> -->
	
</section>

<div class="row">






</body>

</html>
